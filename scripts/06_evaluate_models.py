import os
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime

# =====================================================
# ğŸ“‚ CONFIGURACIÃ“N GENERAL
# =====================================================
REPO_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
LOGS_DIR = os.path.join(REPO_ROOT, "logs")
REPORTS_DIR = os.path.join(REPO_ROOT, "reports")

os.makedirs(REPORTS_DIR, exist_ok=True)

LOG_FILE = os.path.join(LOGS_DIR, "model_training_log.csv")

# =====================================================
# ğŸ§  FUNCIONES AUXILIARES
# =====================================================
def log(msg):
    print(msg)

def load_logs():
    if not os.path.exists(LOG_FILE):
        raise FileNotFoundError(f"âŒ No se encontrÃ³ archivo de logs: {LOG_FILE}")
    df = pd.read_csv(LOG_FILE)
    log(f"âœ… Logs cargados correctamente.\nğŸ“Š Total de registros: {len(df)}")
    return df

def generate_summary(df):
    grouped = df.groupby("model")[["accuracy", "precision", "recall", "f1"]].mean().round(3)
    log("\nğŸ“Š MÃ©tricas promedio por tipo de modelo:")
    print(grouped)

    best_models = df.loc[df.groupby("model")["f1"].idxmax()]
    log("\nğŸ† Mejores modelos por tipo:")
    print(best_models[["model", "timestamp", "accuracy", "f1", "dataset"]])
    return grouped, best_models

def plot_performance(df):
    plt.figure(figsize=(8, 5))
    grouped = df.groupby("model")[["accuracy", "f1"]].mean().reset_index()
    plt.bar(grouped["model"], grouped["accuracy"], label="Accuracy", alpha=0.6)
    plt.bar(grouped["model"], grouped["f1"], label="F1 Score", alpha=0.6)
    plt.title("ğŸ“ˆ Average Model Performance")
    plt.xlabel("Model Type")
    plt.ylabel("Score")
    plt.legend()
    plt.grid(True, linestyle="--", alpha=0.5)

    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    chart_path = os.path.join(REPORTS_DIR, f"model_performance_{ts}.png")
    plt.savefig(chart_path, bbox_inches="tight")
    plt.close()
    log(f"\nğŸ–¼ï¸ GrÃ¡fica guardada: {chart_path}")
    return chart_path

def generate_html_report(summary_df, best_df, chart_path):
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    html_path = os.path.join(REPORTS_DIR, f"model_evaluation_report_{ts}.html")

    html = f"""
    <html>
    <head><title>Football ML Model Evaluation</title></head>
    <body style='font-family:Arial; margin:40px;'>
    <h1>âš½ Football Prediction Model Evaluation Report</h1>
    <h3>Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</h3>
    <hr>
    <h2>ğŸ“Š Average Metrics</h2>
    {summary_df.to_html(border=0, justify='center')}
    <hr>
    <h2>ğŸ† Best Models per Category</h2>
    {best_df.to_html(border=0, justify='center')}
    <hr>
    <h2>ğŸ“ˆ Performance Chart</h2>
    <img src="{os.path.basename(chart_path)}" width="600">
    </body>
    </html>
    """

    with open(html_path, "w") as f:
        f.write(html)

    log(f"ğŸ“„ Reporte HTML generado: {html_path}")
    return html_path

# =====================================================
# ğŸš€ MAIN
# =====================================================
if __name__ == "__main__":
    try:
        df = load_logs()
        summary, best = generate_summary(df)
        chart = plot_performance(df)
        report = generate_html_report(summary, best, chart)
        log("\nâœ… EvaluaciÃ³n completada con Ã©xito.")
        log("Abre el archivo HTML generado para visualizar resultados de forma interactiva.")
    except Exception as e:
        log(f"âŒ Error durante la evaluaciÃ³n: {e}")
        exit(1)
